# üåÄ Avalia√ß√£o de N√≠vel

> Documenta√ß√£o necess√°rio para a solu√ß√£o proposta da avalia√ß√£o t√©cnica da Mobit. 

## üìã Descri√ß√£o

Este projeto √© desenvolvido em **Python 3.12** e utiliza o [`uv`](https://github.com/astral-sh/uv) como gerenciador de pacotes. O `uv` oferece desempenho superior e gerenciamento simplificado de depend√™ncias, substituindo ferramentas tradicionais como `pip`, `virtualenv` e `conda`.

## üèóÔ∏è Estrutura de Diret√≥rios

```
mobit_challenge/
‚îú‚îÄ‚îÄ data/            # Dados de entrada
‚îú‚îÄ‚îÄ models/          # Pesos treinados das redes
‚îú‚îÄ‚îÄ results/
    ‚îú‚îÄ‚îÄ parte_1 # output_image.png
    ‚îú‚îÄ‚îÄ parte_2 # predict/image0.jpg
    ‚îú‚îÄ‚îÄ parte_3 # Gr√°ficos e m√©tricas geradas dos modelos
‚îú‚îÄ‚îÄ src/             # dataset.py, train.py, eval.py, models.py, ...
‚îú‚îÄ‚îÄ utils/           # Fun√ß√µes utilit√°rias (metrics.py e data.py)
‚îú‚îÄ‚îÄ part_1.py        # Script parte 1
‚îú‚îÄ‚îÄ part_2.py        # Script parte 2
‚îú‚îÄ‚îÄ part_3.py        # Script parte 3
‚îú‚îÄ‚îÄ
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```


## üß± Estrutura da Avalia√ß√£o

O projeto est√° dividido nas seguintes etapas:

### üîπ Parte 1 ‚Äì Processamento Digital de Imagens
Algoritmos de pr√©-processamento, transforma√ß√µes e an√°lise de imagens.

### üîπ Parte 2 ‚Äì Contagem de Pessoas com YOLOv8
Uso do YOLOv8 para contagem de pessoas a partir da dete√ß√£o.

### üîπ Parte 3 ‚Äì Classificador de Tipos de Carros
Aplica√ß√£o pr√°tica de um modelo treinado para identifica√ß√£o e classifica√ß√£o de ve√≠culos a partir de imagens.

## üõ†Ô∏è Requisitos

- Python >= 3.11
- `uv` instalado globalmente
- CUDA Toolkit instalado (opcional, mas recomendado para para acelera√ß√£o por GPU)
  - Vers√£o do CUDA = 11.8

### Como instalar o `uv`

```bash
curl -Ls https://astral.sh/uv/install.sh | bash 
```

## ‚öôÔ∏è Como rodar o projeto

```
uv venv
```

```
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

```
uv pip install -r requirements.txt
```

Somente ap√≥s instalar as depend√™ncias, instale separadamente o torch baseado na versao do seu CUDA
```
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ‚öôÔ∏è Resultados e Discuss√µes

### Parte 1
T√©cnicas usadas na pipeline de PDI

Pr√©-processamento: suaviza√ß√£o usando "GaussianBlur"

Processamento: segmenta√ß√£o testando 3 abordagens diferentes, threshold fixo, threshold de otsu, threshold adaptativo gaussiano e, por fim, dete√ß√£o de contornos usando o algoritmo canny.

P√≥s-processamento: suaviza√ß√£o de contornos

Resultados comparativos:

![Comparativo das imagens segmentadas](results/parte_1/comparative_tresholds.png)

![Comparativo das dete√ß√£o de objetos](results/parte_1/comparativo_obj_detectados.png)

### Parte 2
Nessa etapa n√£o houveram dificuldades vistas. O ponto crucial foi a escolha da varia√ß√£o do YOLOv8.

Pensamento inicial: iniciar pelo modelo pr√©-treinado mais leve, ou seja, o `yolov8n.pt`. Como j√° obtivemos o resultado desejado (n√∫mero de pessoas na imagem) usando ele sem a necessidade de transfer-learning/fine-tuning, decidimos apenas complementar essa se√ß√£o de resultados usando a vers√£o seguinte (com mais par√¢metros, mas ainda leve) para fins de maiores confiabilidades, pois observou-se que algumas pessoas, apesar de terem sidos detectadas, foram com baixas confiabilidades.

Resultados comparativos:

![Infer√™ncia YOLOv8n](results/parte_2/n/predict/image0.jpg)

![Infer√™ncia YOLOv8s](results/parte_2/s/predict/image0.jpg)

### Parte 3
Durante a solu√ß√£o desse problema foi notado que, ap√≥s aglutina√ß√£o das classes, apresentou-se um problema de desbalanceamento de classe e, portanto, precisavamos contornar isso de alguma maneira. Algumas abordagens adotadas que obtiveram resultados surpreendentes foram:

`Modifica√ß√£o na fun√ß√£o de perda:`

Quando pensamos em tarefas de classifica√ß√µes simples/tradicionais, usamos a `CrossEntropyLoss `, no entanto, o uso dessa fun√ß√£o n√£o leva em considera√ß√£o as classes minorit√°rias, logo tende a inviesar o modelo durante o treinamento, para tanto, decidimos usar a variante dessa fun√ß√£o, a `CrossEntropyLoss` que usa pesos das classes para penalizar classes maiorit√°rias.

Quando pensamos em tarefas de classifica√ß√µes simples/tradicionais, usa-se a `CrossEntropyLoss`, no entanto, isso pode fazer com que o modelo priorize as classes mais frequentes, ignorando as minorit√°rias, ajustando demais os modelos as classes maiorit√°rias durante o treinamento, portanto decidi usar a vers√£o ponderada da `CrossEntropyLoss`, __atribuindo pesos inversamente proporcionais √† frequ√™ncia de cada classe__. Pois, dessa forma, o erro nas classes minorit√°rias tem maior impacto no processo de aprendizagem, tornando o modelo menos enviesado e mais generalista.

`Data augmentation:`
Usamos um multiplicador de x8 em rela√ß√£o ao n√∫mero de amostras das classes minorit√°rias para que fique relativamente igual o n√∫mero de amostras de cada classe.
- Resize((img_size, img_size))
- RandomHorizontalFlip(p=0.5)
- RandomRotation(degrees=15)
- ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)
- RandomAffine(degrees=0, translate=(0.1, 0.1))

`Transfer-learning (tl)` e `Fine-tuning (ft)`

Weight_Decay:
Adicionar uma penaliza√ß√£o ao valor dos pesos da rede durante o treinamento para evitar o overfitting e melhorar na generaliza√ß√£o das redes.

Resultados comparativos:
Para fins resumidos, iremos plotar somente os melhores resultados entre os m√©todos entre transfer-learning e fine-tuning (ambos os resultados est√£o no diret√≥rio de `results/parte_3`).

### ConNext_Tiny
![](results/parte_3/ft/ConvNeXt_Tiny.png)

![](results/parte_3/ft/ConvNeXt_roc_curve.png)

![](results/parte_3/ft/ConvNeXt_PRF1.png)

Na infer√™ncia:
![](results/parte_3/ft/ConvNeXt_matriz_confusao.png)

### EfficientNetV2s
![](results/parte_3/ft/EfficientNetV2s.png)

![](results/parte_3/ft/EfficientNetV2_roc_curve.png)

![](results/parte_3/ft/EfficientNetV2_PRF1.png)

Na infer√™ncia:
![](results/parte_3/ft/EfficientNetV2_matriz_confusao.png)

### ResNet50
![](results/parte_3/ft/ResNet50.png)

![](results/parte_3/ft/ResNet50_roc_curve.png)

![](results/parte_3/ft/ResNet50_PRF1.png)

Na infer√™ncia:
![](results/parte_3/ft/ResNet50_matriz_confusao.png)

## Discuss√µes pr√©vias

- As principais dificuldades ocorreram devido ao desbalanceamento de classes e √† limita√ß√£o de dados.
- O uso de data augmentation e loss ponderado ajudou, mas o modelo ainda pode ser melhorado com mais dados reais das classes minorit√°rias.
- Em tarefas futuras, pode-se investigar ensemble de modelos.
- Na Parte 1, apesar do threshold fixo ter levado a melhor ele pode nao ser a melhor op√ß√£o para tarefas automatizadas, portanto, a melhor op√ß√£o (sem necessidade de ajuste manual no threshold) √© o uso do Threshold de Otsu.